{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02015ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T02:40:30.522881Z",
     "start_time": "2023-06-16T02:40:26.143080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .support_message_main_box {\n",
       "                position: relative;\n",
       "                display: table-cell;\n",
       "                vertical-align: middle;\n",
       "                width: 100%;\n",
       "                height: 8em;\n",
       "                padding: 1em;\n",
       "                padding-left: 11em;\n",
       "                background-color: #f7f7f7;\n",
       "                border: 1px solid #cfcfcf;\n",
       "                border-radius: 2px;\n",
       "            }\n",
       "            .support_message_main_box img {\n",
       "                position: absolute;\n",
       "                height: 9em;\n",
       "                width: 9em;\n",
       "                left: 0.5em;\n",
       "                top: 0.5em;\n",
       "                border-radius: 1em;\n",
       "            }\n",
       "        </style>\n",
       "        <div class=\"support_message_main_box\">\n",
       "            <img src=\"https://avatars.githubusercontent.com/u/7738570?v=4\" />\n",
       "            <p>\n",
       "            <b>Hi!</b><br/>\n",
       "            <span>I am the author of\n",
       "            <a href=\"https://github.com/LucaCappelletti94/silence_tensorflow\" target=\"_blank\">\n",
       "                silence_tensorflow\n",
       "            </a>, which you use in this Notebook.\n",
       "            </span><br/>\n",
       "            \n",
       "        <span>I hope my work has saved you some time!</span><br/>\n",
       "        \n",
       "            <span>I love to code, but I also need coffee.</span>\n",
       "            <a href=\"https://github.com/sponsors/LucaCappelletti94\" target=\"_blank\">\n",
       "                Please sponsor me on GitHub ‚ù§Ô∏è\n",
       "            </a><br/>\n",
       "            <i>Good luck in your coding üçÄ!</i>\n",
       "            <br/>\n",
       "            <i>- Luca</i>\n",
       "            </p>\n",
       "        <div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7483232799281881318\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15337455616\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9522336491907571479\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.layers import Conv2D, ZeroPadding2D, DepthwiseConv2D\n",
    "from keras.layers import Input, Dense, Dropout, MultiHeadAttention, GlobalAvgPool2D\n",
    "from keras.layers import BatchNormalization, LayerNormalization\n",
    "from keras.layers import Add, Reshape, Concatenate, Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f4866d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T02:40:30.539931Z",
     "start_time": "2023-06-16T02:40:30.535422Z"
    }
   },
   "outputs": [],
   "source": [
    "class HPR:\n",
    "    IMG_SIZE = 256\n",
    "    PATCH_SIZE = 4 # 2x2, transformer block\n",
    "    EXPANSION_FACTOR = 2 # MobileNetV2 blocks\n",
    "    LEARNING_RATE = 0.002\n",
    "    LABEL_SMMOTHING_FACTOR = 0.1\n",
    "    EPOCHS = 300\n",
    "    BATCH_SIZE = 32\n",
    "    SEED = 41\n",
    "    N_CLASS = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dc98a2f",
   "metadata": {},
   "source": [
    "# MobileViT Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78405fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T02:40:30.556108Z",
     "start_time": "2023-06-16T02:40:30.542272Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters=16, kernel_size=3, strides=2):\n",
    "    conv_layer = Conv2D(filters, \n",
    "                        kernel_size, \n",
    "                        strides=strides, \n",
    "                        activation=tf.nn.swish, \n",
    "                        padding=\"same\")\n",
    "    return conv_layer(x)\n",
    "\n",
    "\n",
    "# Reference: https://git.io/JKgtC\n",
    "\n",
    "\n",
    "def inverted_residual_block(x, expanded_channels, output_channels, strides=1):\n",
    "    m = Conv2D(expanded_channels, 1, padding=\"same\", use_bias=False)(x)\n",
    "    m = BatchNormalization()(m)\n",
    "    m = tf.nn.swish(m)\n",
    "\n",
    "    if strides == 2:\n",
    "        m = ZeroPadding2D(padding=imagenet_utils.correct_pad(m, 3))(m)\n",
    "    m = DepthwiseConv2D(3, \n",
    "                        strides=strides, \n",
    "                        padding=\"same\" if strides == 1 else \"valid\", \n",
    "                        use_bias=False)(m)\n",
    "    m = BatchNormalization()(m)\n",
    "    m = tf.nn.swish(m)\n",
    "\n",
    "    m = Conv2D(output_channels, 1, padding=\"same\", use_bias=False)(m)\n",
    "    m = BatchNormalization()(m)\n",
    "\n",
    "    if tf.math.equal(x.shape[-1], output_channels) and strides == 1:\n",
    "        return Add()([m, x])\n",
    "    return m\n",
    "\n",
    "\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = Dense(units, activation=tf.nn.swish)(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def transformer_block(x, transformer_layers, projection_dim, num_heads=2):\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = LayerNormalization(epsilon=1e-6)(x)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = MultiHeadAttention(num_heads=num_heads, \n",
    "                                              key_dim=projection_dim, \n",
    "                                              dropout=0.1)(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = Add()([attention_output, x])\n",
    "        # Layer normalization 2.\n",
    "        x3 = LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=[x.shape[-1] * 2, x.shape[-1]], dropout_rate=0.1,)\n",
    "        # Skip connection 2.\n",
    "        x = Add()([x3, x2])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def mobilevit_block(x, num_blocks, projection_dim, strides=1):\n",
    "    # Local projection with convolutions.\n",
    "    local_features = conv_block(x, filters=projection_dim, strides=strides)\n",
    "    local_features = conv_block(local_features, \n",
    "                                filters=projection_dim, \n",
    "                                kernel_size=1, \n",
    "                                strides=strides)\n",
    "\n",
    "    # Unfold into patches and then pass through Transformers.\n",
    "    num_patches = int((local_features.shape[1] * local_features.shape[2]) / HPR.PATCH_SIZE)\n",
    "    non_overlapping_patches = Reshape((HPR.PATCH_SIZE, \n",
    "                                       num_patches, \n",
    "                                       projection_dim))(local_features)\n",
    "    global_features = transformer_block(non_overlapping_patches, \n",
    "                                        num_blocks, \n",
    "                                        projection_dim)\n",
    "\n",
    "    # Fold into conv-like feature-maps.\n",
    "    folded_feature_map = Reshape((*local_features.shape[1:-1], \n",
    "                                  projection_dim))(global_features)\n",
    "\n",
    "    # Apply point-wise conv -> concatenate with the input features.\n",
    "    folded_feature_map = conv_block(folded_feature_map, \n",
    "                                    filters=x.shape[-1], \n",
    "                                    kernel_size=1, \n",
    "                                    strides=strides)\n",
    "    local_global_features = Concatenate(axis=-1)([x, folded_feature_map])\n",
    "\n",
    "    # Fuse the local and global features using a convoluion layer.\n",
    "    local_global_features = conv_block(local_global_features, \n",
    "                                       filters=projection_dim, \n",
    "                                       strides=strides)\n",
    "\n",
    "    return local_global_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8d2421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T02:40:33.501994Z",
     "start_time": "2023-06-16T02:40:30.567336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)          (None, 256, 256, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 16  448         ['rescaling[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 32  512         ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 128, 32  128        ['conv2d_1[0][0]']               \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.silu (TFOpLambda)        (None, 128, 128, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d (DepthwiseCon  (None, 128, 128, 32  288        ['tf.nn.silu[0][0]']             \n",
      " v2D)                           )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 128, 32  128        ['depthwise_conv2d[0][0]']       \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.silu_1 (TFOpLambda)      (None, 128, 128, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 16  512         ['tf.nn.silu_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 16  64         ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 128, 128, 16  0           ['batch_normalization_2[0][0]',  \n",
      "                                )                                 'conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 32  512         ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 32  128        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.silu_2 (TFOpLambda)      (None, 128, 128, 32  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 129, 129, 32  0          ['tf.nn.silu_2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (DepthwiseC  (None, 64, 64, 32)  288         ['zero_padding2d[0][0]']         \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 32)  128         ['depthwise_conv2d_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.silu_3 (TFOpLambda)      (None, 64, 64, 32)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 24)   768         ['tf.nn.silu_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 24)  96          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 48)   1152        ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 64, 64, 48)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.silu_4 (TFOpLambda)      (None, 64, 64, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (DepthwiseC  (None, 64, 64, 48)  432         ['tf.nn.silu_4[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64, 64, 48)  192         ['depthwise_conv2d_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.silu_5 (TFOpLambda)      (None, 64, 64, 48)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 64, 24)   1152        ['tf.nn.silu_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 64, 24)  96          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " add_1 (Add)                    (None, 64, 64, 24)   0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 64, 64, 48)   1152        ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 64, 64, 48)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.silu_6 (TFOpLambda)      (None, 64, 64, 48)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " depthwise_conv2d_3 (DepthwiseC  (None, 64, 64, 48)  432         ['tf.nn.silu_6[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 64, 64, 48)  192         ['depthwise_conv2d_3[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.silu_7 (TFOpLambda)      (None, 64, 64, 48)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 64, 24)   1152        ['tf.nn.silu_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 64, 64, 24)  96          ['conv2d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 64, 64, 24)   0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 64, 64, 48)   1152        ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 64, 64, 48)  192         ['conv2d_9[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.silu_8 (TFOpLambda)      (None, 64, 64, 48)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 65, 65, 48)  0           ['tf.nn.silu_8[0][0]']           \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_4 (DepthwiseC  (None, 32, 32, 48)  432         ['zero_padding2d_1[0][0]']       \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 48)  192         ['depthwise_conv2d_4[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.silu_9 (TFOpLambda)      (None, 32, 32, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 48)   2304        ['tf.nn.silu_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 32, 32, 48)  192         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 64)   27712       ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 64)   4160        ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 4, 256, 64)   0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 4, 256, 64)  128         ['reshape[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 4, 256, 64)  33216       ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 4, 256, 64)   0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 4, 256, 64)  128         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4, 256, 128)  8320        ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4, 256, 128)  0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4, 256, 64)   8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4, 256, 64)   0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 4, 256, 64)   0           ['dropout_1[0][0]',              \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 4, 256, 64)  128         ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 4, 256, 64)  33216       ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 4, 256, 64)   0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 4, 256, 64)  128         ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4, 256, 128)  8320        ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 256, 128)  0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4, 256, 64)   8256        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4, 256, 64)   0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 4, 256, 64)   0           ['dropout_3[0][0]',              \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 32, 32, 64)   0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 48)   3120        ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 96)   0           ['batch_normalization_14[0][0]', \n",
      "                                                                  'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 32, 32, 64)   55360       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 32, 32, 128)  8192        ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 32, 32, 128)  512        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.silu_10 (TFOpLambda)     (None, 32, 32, 128)  0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadding2  (None, 33, 33, 128)  0          ['tf.nn.silu_10[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_5 (DepthwiseC  (None, 16, 16, 128)  1152       ['zero_padding2d_2[0][0]']       \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 16, 128)  512        ['depthwise_conv2d_5[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.silu_11 (TFOpLambda)     (None, 16, 16, 128)  0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 16, 16, 64)   8192        ['tf.nn.silu_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 16, 64)  256         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 16, 16, 80)   46160       ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 16, 16, 80)   6480        ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 4, 64, 80)    0           ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 4, 64, 80)   160         ['reshape_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 4, 64, 80)   51760       ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 4, 64, 80)    0           ['multi_head_attention_2[0][0]', \n",
      "                                                                  'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 4, 64, 80)   160         ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4, 64, 160)   12960       ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 4, 64, 160)   0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 4, 64, 80)    12880       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 4, 64, 80)    0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 4, 64, 80)    0           ['dropout_5[0][0]',              \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 4, 64, 80)   160         ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 4, 64, 80)   51760       ['layer_normalization_6[0][0]',  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 4, 64, 80)    0           ['multi_head_attention_3[0][0]', \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 4, 64, 80)   160         ['add_9[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4, 64, 160)   12960       ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 4, 64, 160)   0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4, 64, 80)    12880       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 4, 64, 80)    0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 4, 64, 80)    0           ['dropout_7[0][0]',              \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 4, 64, 80)   160         ['add_10[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 4, 64, 80)   51760       ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 4, 64, 80)    0           ['multi_head_attention_4[0][0]', \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 4, 64, 80)   160         ['add_11[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 4, 64, 160)   12960       ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 4, 64, 160)   0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 4, 64, 80)    12880       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 4, 64, 80)    0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 4, 64, 80)    0           ['dropout_9[0][0]',              \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 4, 64, 80)   160         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 4, 64, 80)   51760       ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 4, 64, 80)    0           ['multi_head_attention_5[0][0]', \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 4, 64, 80)   160         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 4, 64, 160)   12960       ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 4, 64, 160)   0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 4, 64, 80)    12880       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 4, 64, 80)    0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 4, 64, 80)    0           ['dropout_11[0][0]',             \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 16, 16, 80)   0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 16, 16, 64)   5184        ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 16, 16, 128)  0           ['batch_normalization_17[0][0]', \n",
      "                                                                  'conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 16, 16, 80)   92240       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 16, 16, 160)  12800       ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 16, 16, 160)  640        ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.silu_12 (TFOpLambda)     (None, 16, 16, 160)  0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadding2  (None, 17, 17, 160)  0          ['tf.nn.silu_12[0][0]']          \n",
      " D)                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " depthwise_conv2d_6 (DepthwiseC  (None, 8, 8, 160)   1440        ['zero_padding2d_3[0][0]']       \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 8, 8, 160)   640         ['depthwise_conv2d_6[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.silu_13 (TFOpLambda)     (None, 8, 8, 160)    0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 8, 8, 80)     12800       ['tf.nn.silu_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 8, 8, 80)    320         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 8, 8, 96)     69216       ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 8, 8, 96)     9312        ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 4, 16, 96)    0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 4, 16, 96)   192         ['reshape_4[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 4, 16, 96)   74400       ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 4, 16, 96)    0           ['multi_head_attention_6[0][0]', \n",
      "                                                                  'reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 4, 16, 96)   192         ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 4, 16, 192)   18624       ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 4, 16, 192)   0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 4, 16, 96)    18528       ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 4, 16, 96)    0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 4, 16, 96)    0           ['dropout_13[0][0]',             \n",
      "                                                                  'add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 4, 16, 96)   192         ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 4, 16, 96)   74400       ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 4, 16, 96)    0           ['multi_head_attention_7[0][0]', \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 4, 16, 96)   192         ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 4, 16, 192)   18624       ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 4, 16, 192)   0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 4, 16, 96)    18528       ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 4, 16, 96)    0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 4, 16, 96)    0           ['dropout_15[0][0]',             \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 4, 16, 96)   192         ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 4, 16, 96)   74400       ['layer_normalization_16[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 4, 16, 96)    0           ['multi_head_attention_8[0][0]', \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 4, 16, 96)   192         ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 4, 16, 192)   18624       ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 4, 16, 192)   0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 4, 16, 96)    18528       ['dropout_16[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 4, 16, 96)    0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 4, 16, 96)    0           ['dropout_17[0][0]',             \n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 8, 8, 96)     0           ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 8, 8, 80)     7760        ['reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8, 8, 160)    0           ['batch_normalization_20[0][0]', \n",
      "                                                                  'conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 8, 8, 96)     138336      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 8, 8, 320)    31040       ['conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 320)         0           ['conv2d_27[0][0]']              \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 5)            1605        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,307,621\n",
      "Trainable params: 1,305,077\n",
      "Non-trainable params: 2,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_mobilevit(tensor, num_classes=HPR.N_CLASS, include_top=True):\n",
    "    # Initial conv-stem -> MV2 block.\n",
    "    x = conv_block(tensor, filters=16)\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=16 * HPR.EXPANSION_FACTOR, output_channels=16\n",
    "    )\n",
    "\n",
    "    # Downsampling with MV2 block.\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=16 * HPR.EXPANSION_FACTOR, output_channels=24, strides=2\n",
    "    )\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=24 * HPR.EXPANSION_FACTOR, output_channels=24\n",
    "    )\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=24 * HPR.EXPANSION_FACTOR, output_channels=24\n",
    "    )\n",
    "\n",
    "    # First MV2 -> MobileViT block.\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=24 * HPR.EXPANSION_FACTOR, output_channels=48, strides=2\n",
    "    )\n",
    "    x = mobilevit_block(x, num_blocks=2, projection_dim=64)\n",
    "\n",
    "    # Second MV2 -> MobileViT block.\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=64 * HPR.EXPANSION_FACTOR, output_channels=64, strides=2\n",
    "    )\n",
    "    x = mobilevit_block(x, num_blocks=4, projection_dim=80)\n",
    "\n",
    "    # Third MV2 -> MobileViT block.\n",
    "    x = inverted_residual_block(\n",
    "        x, expanded_channels=80 * HPR.EXPANSION_FACTOR, output_channels=80, strides=2\n",
    "    )\n",
    "    x = mobilevit_block(x, num_blocks=3, projection_dim=96)\n",
    "    x = conv_block(x, filters=320, kernel_size=1, strides=1)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification head.\n",
    "        x = GlobalAvgPool2D()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "inputs = Input((HPR.IMG_SIZE, HPR.IMG_SIZE, 3))\n",
    "x = Rescaling(scale=1.0 / 255)(inputs)\n",
    "x = create_mobilevit(x, include_top=False)\n",
    "x = GlobalAvgPool2D()(x)\n",
    "outputs = Dense(HPR.N_CLASS, activation=\"softmax\")(x)\n",
    "mobilevit_xxs = Model(inputs, outputs)\n",
    "mobilevit_xxs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "785d25a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T02:40:33.507915Z",
     "start_time": "2023-06-16T02:40:33.504492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), name='dense_18/Softmax:0', description=\"created by layer 'dense_18'\")\n"
     ]
    }
   ],
   "source": [
    "print(mobilevit_xxs.input)\n",
    "print(mobilevit_xxs.output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (NGC 22.02 / TensorFlow 2.7) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
